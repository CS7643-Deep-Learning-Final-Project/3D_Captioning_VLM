data:
  hf_repo: "tiange/Cap3D"
  hf_file: "Cap3D_automated_ShapeNet.csv"
  split_train: "train"     # or custom slice/filter logic
  split_val: "validation"
  streaming: true
  point_cloud_size: 1024
  batch_size: 64          # Increased for H100 (was 16)
  num_workers: 12         # Increased from 2 for better data loading parallelism
  prefetch_factor: 4      # Prefetch 4 batches per worker
  persistent_workers: true # Keep workers alive between epochs

model:
  encoder_type: "dgcnn"  # "point_bert" or "dgcnn"
  embed_dim: 768
  output_dim: 2048
  decoder_name: "gpt2"

training:
  learning_rate: 1.0e-5
  num_epochs: 50
  warmup_steps: 1000
  max_length: 128
  optimizer: "adamw"
  scheduler: "cosine"
  weight_decay: 0.01
  grad_accum_steps: 1
  max_norm: 1.0
  num_beams: 3
  save_top_k: 3
  amp: true
  pad_token_id: -100
  # use_compile: true  # Enable torch.compile for H100 optimization

evaluation:
  metrics: ["bleu", "cider", "rouge-l", "bertscore"]
  main_metric: "cider"
  eval_frequency: 1
